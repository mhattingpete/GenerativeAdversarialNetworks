{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN for MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from viz import updatable_display2\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from generators import Generator\n",
    "from discriminators import Discriminator\n",
    "from utils import img2vec,vec2img,sample_noise,true_target,fake_target\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28\n",
    "\n",
    "compose = transforms.Compose([transforms.ToTensor(),transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\n",
    "dataset = datasets.MNIST(root='MNIST',train=True,transform=compose,download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "m = int(np.sqrt(batch_size))-1 # the sqrt of number of test samples\n",
    "lr = 1e-4\n",
    "dropout_prob = 0.3\n",
    "noise_dim = 100\n",
    "output_size = image_size**2\n",
    "\n",
    "num_test_samples = m**2\n",
    "test_noise = sample_noise(num_test_samples,noise_dim,device)\n",
    "\n",
    "# intialize models\n",
    "generator = Generator(hidden_sizes=[noise_dim,256,512,1024,output_size],dropout_prob=0).to(device)\n",
    "discriminator = Discriminator(hidden_sizes=[output_size,1024,512,256,1],dropout_prob=dropout_prob).to(device)\n",
    "\n",
    "# otpimizers\n",
    "g_optimizer = optim.Adam(generator.parameters(),lr=lr)\n",
    "d_optimizer = optim.Adam(discriminator.parameters(),lr=lr)\n",
    "loss_fun = nn.BCELoss()\n",
    "\n",
    "# data loader\n",
    "data_loader = DataLoader(dataset,batch_size=batch_size,shuffle=True)\n",
    "\n",
    "# Create logger instance\n",
    "dis = updatable_display2(['train'],[\"epoch\",\"d_error\",\"g_error\"])\n",
    "# Total number of epochs to train\n",
    "num_epochs = 200\n",
    "global_step = 0\n",
    "epoch = 0\n",
    "d_error = 0\n",
    "g_error = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(noise,optimizer):\n",
    "    '''\n",
    "    Train the generator to generate realistic samples and thereby fool the discriminator\n",
    "    '''\n",
    "    N = noise.size(0)\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Sample noise and generate fake data\n",
    "    prediction = discriminator(noise)\n",
    "    loss = loss_fun(prediction,true_target(N,device))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(real_data,fake_data,optimizer):\n",
    "    '''\n",
    "    Train the discriminator to distinguish between real and fake data\n",
    "    '''\n",
    "    N = real_data.size(0)\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 1.1 Train on Real Data\n",
    "    prediction_real = discriminator(real_data)\n",
    "    loss_real = loss_fun(prediction_real,true_target(N,device))\n",
    "    loss_real.backward()\n",
    "\n",
    "    # 1.2 Train on Fake Data\n",
    "    prediction_fake = discriminator(fake_data)\n",
    "    loss_fake = loss_fun(prediction_fake,fake_target(N,device))\n",
    "    loss_fake.backward()\n",
    "    \n",
    "    # 1.3 Update weights with gradients\n",
    "    optimizer.step()\n",
    "    return loss_real + loss_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen_steps = 1\n",
    "gen_train_freq = 5\n",
    "try:\n",
    "    while epoch < num_epochs:\n",
    "        for n_batch,(real_batch,_) in enumerate(data_loader):\n",
    "            N = real_batch.size(0)\n",
    "            # 1. Train Discriminator\n",
    "            real_data = img2vec(real_batch).to(device)\n",
    "            # Generate fake data and detach \n",
    "            # (so gradients are not calculated for generator)\n",
    "            noise_tensor = sample_noise(N,noise_dim,device)\n",
    "            with torch.no_grad():\n",
    "                fake_data = generator(noise_tensor).detach()\n",
    "            # Train D\n",
    "            d_error = train_discriminator(real_data,fake_data,d_optimizer)\n",
    "\n",
    "            # 2. Train Generator every 'gen_train_freq' steps\n",
    "            if global_step % gen_train_freq == 0:\n",
    "                for _ in range(gen_steps):\n",
    "                    # Generate fake data\n",
    "                    fake_data = generator(sample_noise(N,noise_dim,device))\n",
    "                    # Train G\n",
    "                    g_error = train_generator(fake_data,g_optimizer)\n",
    "                    g_error = g_error.item()\n",
    "\n",
    "            # Log batch error and delete tensors\n",
    "            dis.update(global_step,'train',{\"epoch\":epoch,\"d_error\":d_error.item(),\"g_error\":g_error} )\n",
    "            global_step += 1\n",
    "            del fake_data\n",
    "            del real_data\n",
    "            del noise_tensor\n",
    "\n",
    "            # Display Progress every few batches\n",
    "            if global_step % 50 == 0:\n",
    "                test_images = vec2img(generator(test_noise),image_size)\n",
    "                test_images = test_images.data\n",
    "                canvas = np.zeros((image_size*m,image_size*m))\n",
    "                q = 0\n",
    "                for i in range(m):\n",
    "                    for j in range(m):\n",
    "                        canvas[i*image_size:(i+1)*image_size,j*image_size:(j+1)*image_size] = test_images[q]\n",
    "                        q += 1\n",
    "                dis.display(scale=True)\n",
    "                plt.figure(figsize=(10,10))\n",
    "                plt.imshow(canvas,cmap='gray')\n",
    "                plt.axis(\"off\")\n",
    "                if epoch % 50 == 0:\n",
    "                    plt.savefig(\"Figures/GAN-MNIST-Epoch=\"+str(epoch)+\".png\")\n",
    "                plt.show()\n",
    "        epoch += 1\n",
    "except:\n",
    "    test_images = vec2img(generator(test_noise),image_size)\n",
    "    test_images = test_images.data\n",
    "    canvas = np.zeros((image_size*m,image_size*m))\n",
    "    q = 0\n",
    "    for i in range(m):\n",
    "        for j in range(m):\n",
    "            canvas[i*image_size:(i+1)*image_size,j*image_size:(j+1)*image_size] = test_images[q]\n",
    "            q+=1\n",
    "    dis.display(scale=True)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(canvas,cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"Figures/GAN-MNIST.png\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
